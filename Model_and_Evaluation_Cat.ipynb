{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wwengm/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split,cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.models import Sequential\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import np_utils\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Adjusted_BoxOffice</th>\n",
       "      <th>BoxOffice</th>\n",
       "      <th>NLP_Score</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Year</th>\n",
       "      <th>imdbRating</th>\n",
       "      <th>imdbVotes</th>\n",
       "      <th>Internet_Movie_Database</th>\n",
       "      <th>Rotten_Tomatoes</th>\n",
       "      <th>...</th>\n",
       "      <th>Sport</th>\n",
       "      <th>Thriller</th>\n",
       "      <th>War</th>\n",
       "      <th>Western</th>\n",
       "      <th>Country_count</th>\n",
       "      <th>budget</th>\n",
       "      <th>Adjusted_Budgets</th>\n",
       "      <th>Director_Score</th>\n",
       "      <th>Writer_Score</th>\n",
       "      <th>Actor_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>9322.000000</td>\n",
       "      <td>9322.000000</td>\n",
       "      <td>9322.000000</td>\n",
       "      <td>9322.000000</td>\n",
       "      <td>9322.000000</td>\n",
       "      <td>9322.000000</td>\n",
       "      <td>9322.000000</td>\n",
       "      <td>9.322000e+03</td>\n",
       "      <td>9322.000000</td>\n",
       "      <td>9322.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>9322.000000</td>\n",
       "      <td>9322.000000</td>\n",
       "      <td>9322.000000</td>\n",
       "      <td>9322.000000</td>\n",
       "      <td>9322.000000</td>\n",
       "      <td>3.428000e+03</td>\n",
       "      <td>3428.000000</td>\n",
       "      <td>9322.000000</td>\n",
       "      <td>9322.000000</td>\n",
       "      <td>9322.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5777.557069</td>\n",
       "      <td>28.648639</td>\n",
       "      <td>21.948306</td>\n",
       "      <td>9.158985</td>\n",
       "      <td>104.624973</td>\n",
       "      <td>2005.691697</td>\n",
       "      <td>6.378696</td>\n",
       "      <td>5.093996e+04</td>\n",
       "      <td>6.378696</td>\n",
       "      <td>5.706821</td>\n",
       "      <td>...</td>\n",
       "      <td>0.031216</td>\n",
       "      <td>0.204784</td>\n",
       "      <td>0.030573</td>\n",
       "      <td>0.011049</td>\n",
       "      <td>1.535078</td>\n",
       "      <td>3.833468e+07</td>\n",
       "      <td>48.302463</td>\n",
       "      <td>1.346707</td>\n",
       "      <td>0.737980</td>\n",
       "      <td>7.074298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3272.476375</td>\n",
       "      <td>64.164851</td>\n",
       "      <td>51.199261</td>\n",
       "      <td>5.261931</td>\n",
       "      <td>17.940863</td>\n",
       "      <td>7.626457</td>\n",
       "      <td>1.004886</td>\n",
       "      <td>1.191995e+05</td>\n",
       "      <td>1.004886</td>\n",
       "      <td>2.639098</td>\n",
       "      <td>...</td>\n",
       "      <td>0.173912</td>\n",
       "      <td>0.403566</td>\n",
       "      <td>0.172167</td>\n",
       "      <td>0.104538</td>\n",
       "      <td>0.974243</td>\n",
       "      <td>4.505118e+07</td>\n",
       "      <td>53.827954</td>\n",
       "      <td>1.062290</td>\n",
       "      <td>0.627913</td>\n",
       "      <td>4.542283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000082</td>\n",
       "      <td>0.000074</td>\n",
       "      <td>1.046110</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>1990.000000</td>\n",
       "      <td>1.100000</td>\n",
       "      <td>6.000000e+00</td>\n",
       "      <td>1.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000e+03</td>\n",
       "      <td>0.009063</td>\n",
       "      <td>0.045814</td>\n",
       "      <td>0.022431</td>\n",
       "      <td>0.621454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2833.250000</td>\n",
       "      <td>0.082429</td>\n",
       "      <td>0.066174</td>\n",
       "      <td>4.624634</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>5.800000</td>\n",
       "      <td>2.052000e+03</td>\n",
       "      <td>5.800000</td>\n",
       "      <td>3.700000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.200000e+06</td>\n",
       "      <td>11.353044</td>\n",
       "      <td>0.501637</td>\n",
       "      <td>0.356760</td>\n",
       "      <td>3.010948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5973.500000</td>\n",
       "      <td>1.657188</td>\n",
       "      <td>1.250904</td>\n",
       "      <td>8.212019</td>\n",
       "      <td>101.000000</td>\n",
       "      <td>2007.000000</td>\n",
       "      <td>6.500000</td>\n",
       "      <td>9.069500e+03</td>\n",
       "      <td>6.500000</td>\n",
       "      <td>5.940134</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.400000e+07</td>\n",
       "      <td>29.612011</td>\n",
       "      <td>0.990688</td>\n",
       "      <td>0.434675</td>\n",
       "      <td>6.192310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8675.750000</td>\n",
       "      <td>29.015950</td>\n",
       "      <td>21.010307</td>\n",
       "      <td>12.778660</td>\n",
       "      <td>113.000000</td>\n",
       "      <td>2012.000000</td>\n",
       "      <td>7.100000</td>\n",
       "      <td>4.437925e+04</td>\n",
       "      <td>7.100000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>5.000000e+07</td>\n",
       "      <td>66.110107</td>\n",
       "      <td>1.865204</td>\n",
       "      <td>0.916846</td>\n",
       "      <td>10.318051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>11115.000000</td>\n",
       "      <td>1039.048028</td>\n",
       "      <td>936.658640</td>\n",
       "      <td>28.108077</td>\n",
       "      <td>197.000000</td>\n",
       "      <td>2018.000000</td>\n",
       "      <td>9.300000</td>\n",
       "      <td>2.018482e+06</td>\n",
       "      <td>9.300000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>4.250000e+08</td>\n",
       "      <td>501.035781</td>\n",
       "      <td>6.481680</td>\n",
       "      <td>5.620875</td>\n",
       "      <td>22.635663</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Unnamed: 0  Adjusted_BoxOffice    BoxOffice    NLP_Score  \\\n",
       "count   9322.000000         9322.000000  9322.000000  9322.000000   \n",
       "mean    5777.557069           28.648639    21.948306     9.158985   \n",
       "std     3272.476375           64.164851    51.199261     5.261931   \n",
       "min        0.000000            0.000082     0.000074     1.046110   \n",
       "25%     2833.250000            0.082429     0.066174     4.624634   \n",
       "50%     5973.500000            1.657188     1.250904     8.212019   \n",
       "75%     8675.750000           29.015950    21.010307    12.778660   \n",
       "max    11115.000000         1039.048028   936.658640    28.108077   \n",
       "\n",
       "           Runtime         Year   imdbRating     imdbVotes  \\\n",
       "count  9322.000000  9322.000000  9322.000000  9.322000e+03   \n",
       "mean    104.624973  2005.691697     6.378696  5.093996e+04   \n",
       "std      17.940863     7.626457     1.004886  1.191995e+05   \n",
       "min      53.000000  1990.000000     1.100000  6.000000e+00   \n",
       "25%      92.000000  2000.000000     5.800000  2.052000e+03   \n",
       "50%     101.000000  2007.000000     6.500000  9.069500e+03   \n",
       "75%     113.000000  2012.000000     7.100000  4.437925e+04   \n",
       "max     197.000000  2018.000000     9.300000  2.018482e+06   \n",
       "\n",
       "       Internet_Movie_Database  Rotten_Tomatoes     ...             Sport  \\\n",
       "count              9322.000000      9322.000000     ...       9322.000000   \n",
       "mean                  6.378696         5.706821     ...          0.031216   \n",
       "std                   1.004886         2.639098     ...          0.173912   \n",
       "min                   1.100000         0.000000     ...          0.000000   \n",
       "25%                   5.800000         3.700000     ...          0.000000   \n",
       "50%                   6.500000         5.940134     ...          0.000000   \n",
       "75%                   7.100000         8.000000     ...          0.000000   \n",
       "max                   9.300000        10.000000     ...          1.000000   \n",
       "\n",
       "          Thriller          War      Western  Country_count        budget  \\\n",
       "count  9322.000000  9322.000000  9322.000000    9322.000000  3.428000e+03   \n",
       "mean      0.204784     0.030573     0.011049       1.535078  3.833468e+07   \n",
       "std       0.403566     0.172167     0.104538       0.974243  4.505118e+07   \n",
       "min       0.000000     0.000000     0.000000       1.000000  6.000000e+03   \n",
       "25%       0.000000     0.000000     0.000000       1.000000  9.200000e+06   \n",
       "50%       0.000000     0.000000     0.000000       1.000000  2.400000e+07   \n",
       "75%       0.000000     0.000000     0.000000       2.000000  5.000000e+07   \n",
       "max       1.000000     1.000000     1.000000      16.000000  4.250000e+08   \n",
       "\n",
       "       Adjusted_Budgets  Director_Score  Writer_Score  Actor_Score  \n",
       "count       3428.000000     9322.000000   9322.000000  9322.000000  \n",
       "mean          48.302463        1.346707      0.737980     7.074298  \n",
       "std           53.827954        1.062290      0.627913     4.542283  \n",
       "min            0.009063        0.045814      0.022431     0.621454  \n",
       "25%           11.353044        0.501637      0.356760     3.010948  \n",
       "50%           29.612011        0.990688      0.434675     6.192310  \n",
       "75%           66.110107        1.865204      0.916846    10.318051  \n",
       "max          501.035781        6.481680      5.620875    22.635663  \n",
       "\n",
       "[8 rows x 41 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('./data/data_combined_budget.csv')\n",
    "data = data[(data.Runtime >= 50) & (data.Runtime <= 200) & \n",
    "            (data.Year >= 1990)]\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f48def1a0b8>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# transfer to category\n",
    "log_boxoffice = np.log(data['Adjusted_BoxOffice'])\n",
    "cat_raw = pd.cut(log_boxoffice, [-10,-6,-4,-2,0,2,4,6,10])\n",
    "all_cats = cat_raw.unique()\n",
    "cat_encoder = dict([(i,x) for x,i in enumerate(all_cats)])\n",
    "data['Adjusted_BoxOffice_Cat'] = cat_raw.replace(cat_encoder)\n",
    "data['Adjusted_BoxOffice_Cat'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Model1: CV Accuracy: 31.663 | Testing Accuracy: 31.641\n",
      "Baseline Model2: CV Accuracy: 40.475 | Testing Accuracy: 41.723\n"
     ]
    }
   ],
   "source": [
    "#Baseline Model: A simple logistic regression\n",
    "\n",
    "data_model1 = data[['Adjusted_BoxOffice_Cat', 'Runtime',\n",
    "        'Action','Adventure', 'Animation', 'Biography', 'Comedy', 'Crime', 'Documentary',\n",
    "       'Drama', 'Family', 'Fantasy', 'Film-Noir', 'History', 'Horror', 'Music',\n",
    "       'Musical', 'Mystery', 'News', 'Romance', 'Sci-Fi', 'Short', 'Sport',\n",
    "       'Thriller', 'War', 'Western', 'Country_count']]\n",
    "\n",
    "X = data_model1.drop('Adjusted_BoxOffice_Cat',axis = 1)\n",
    "y = data_model1['Adjusted_BoxOffice_Cat']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3,random_state = 1)\n",
    "\n",
    "\n",
    "lr_clf = LogisticRegression()\n",
    "scores = cross_val_score(lr_clf, X_train, y_train, cv=5)\n",
    "\n",
    "lr_clf.fit(X_train, y_train)\n",
    "y_pred = lr_clf.predict(X_test)\n",
    "tst_acc = accuracy_score(y_test, y_pred) * 100\n",
    "cv_acc = np.mean(scores) * 100\n",
    "print('Baseline Model1: CV Accuracy: %0.3f | Testing Accuracy: %0.3f' % (cv_acc,tst_acc))\n",
    "\n",
    "\n",
    "data_model2 = data[['Adjusted_BoxOffice_Cat', 'Runtime','Year', 'imdbRating', 'imdbVotes',\n",
    "       'Internet_Movie_Database', 'Rotten_Tomatoes', 'Metacritic',\n",
    "       'Action','Adventure', 'Animation', 'Biography', 'Comedy', 'Crime', 'Documentary',\n",
    "       'Drama', 'Family', 'Fantasy', 'Film-Noir', 'History', 'Horror', 'Music',\n",
    "       'Musical', 'Mystery', 'News', 'Romance', 'Sci-Fi', 'Short', 'Sport',\n",
    "       'Thriller', 'War', 'Western', 'Country_count']]\n",
    "\n",
    "X = data_model2.drop('Adjusted_BoxOffice_Cat',axis = 1)\n",
    "y = data_model2['Adjusted_BoxOffice_Cat']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3,random_state = 1)\n",
    "\n",
    "\n",
    "lr_clf = LogisticRegression()\n",
    "scores = cross_val_score(lr_clf, X_train, y_train, cv=5)\n",
    "\n",
    "lr_clf.fit(X_train, y_train)\n",
    "y_pred = lr_clf.predict(X_test)\n",
    "tst_acc = accuracy_score(y_test, y_pred) * 100\n",
    "cv_acc = np.mean(scores) * 100\n",
    "print('Baseline Model2: CV Accuracy: %0.3f | Testing Accuracy: %0.3f' % (cv_acc,tst_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR(NLP): CV Accuracy: 35.585 | Testing Accuracy: 36.539\n",
      "LR(NLP_SeparatedScore): CV Accuracy: 36.243 | Testing Accuracy: 36.825\n"
     ]
    }
   ],
   "source": [
    "# LR with NLP\n",
    "data_model3 = data[['Adjusted_BoxOffice_Cat', 'Runtime',\n",
    "        'Action','Adventure', 'Animation', 'Biography', 'Comedy', 'Crime', 'Documentary',\n",
    "       'Drama', 'Family', 'Fantasy', 'Film-Noir', 'History', 'Horror', 'Music',\n",
    "       'Musical', 'Mystery', 'News', 'Romance', 'Sci-Fi', 'Short', 'Sport',\n",
    "       'Thriller', 'War', 'Western', 'Country_count','NLP_Score']]\n",
    "\n",
    "X = data_model3.drop('Adjusted_BoxOffice_Cat',axis = 1)\n",
    "y = data_model3['Adjusted_BoxOffice_Cat']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3,random_state = 1)\n",
    "\n",
    "\n",
    "lr_clf = LogisticRegression()\n",
    "scores = cross_val_score(lr_clf, X_train, y_train, cv=5)\n",
    "\n",
    "lr_clf.fit(X_train, y_train)\n",
    "y_pred = lr_clf.predict(X_test)\n",
    "tst_acc = accuracy_score(y_test, y_pred) * 100\n",
    "cv_acc = np.mean(scores) * 100\n",
    "print('LR(NLP): CV Accuracy: %0.3f | Testing Accuracy: %0.3f' % (cv_acc,tst_acc))\n",
    "\n",
    "\n",
    "data_model3a = data[['Adjusted_BoxOffice_Cat', 'Runtime',\n",
    "        'Action','Adventure', 'Animation', 'Biography', 'Comedy', 'Crime', 'Documentary',\n",
    "       'Drama', 'Family', 'Fantasy', 'Film-Noir', 'History', 'Horror', 'Music',\n",
    "       'Musical', 'Mystery', 'News', 'Romance', 'Sci-Fi', 'Short', 'Sport',\n",
    "       'Thriller', 'War', 'Western', 'Country_count','Director_Score','Writer_Score','Actor_Score']]\n",
    "\n",
    "\n",
    "X = data_model3a.drop('Adjusted_BoxOffice_Cat',axis = 1)\n",
    "y = data_model3a['Adjusted_BoxOffice_Cat']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3,random_state = 1)\n",
    "\n",
    "\n",
    "lr_clf = LogisticRegression()\n",
    "scores = cross_val_score(lr_clf, X_train, y_train, cv=5)\n",
    "\n",
    "lr_clf.fit(X_train, y_train)\n",
    "y_pred = lr_clf.predict(X_test)\n",
    "tst_acc = accuracy_score(y_test, y_pred) * 100\n",
    "cv_acc = np.mean(scores) * 100\n",
    "print('LR(NLP_SeparatedScore): CV Accuracy: %0.3f | Testing Accuracy: %0.3f' % (cv_acc,tst_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM: CV Accuracy: 34.682 | Testing Accuracy: 35.967\n",
      "SVM(NLP_SeparatedScore): CV Accuracy: 34.912 | Testing Accuracy: 36.682\n"
     ]
    }
   ],
   "source": [
    "# SVM\n",
    "data_model4 = data_model3\n",
    "X = data_model4.drop('Adjusted_BoxOffice_Cat',axis = 1)\n",
    "y = data_model4['Adjusted_BoxOffice_Cat']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3,random_state = 1)\n",
    "\n",
    "\n",
    "svm_clf = svm.SVC(decision_function_shape='ovo')\n",
    "scores = cross_val_score(svm_clf, X_train, y_train, cv=5)\n",
    "\n",
    "svm_clf.fit(X_train, y_train)\n",
    "y_pred = svm_clf.predict(X_test)\n",
    "tst_acc = accuracy_score(y_test, y_pred) * 100\n",
    "cv_acc = np.mean(scores) * 100\n",
    "print('SVM: CV Accuracy: %0.3f | Testing Accuracy: %0.3f' % (cv_acc,tst_acc))\n",
    "\n",
    "\n",
    "data_model4a = data_model3a\n",
    "X = data_model4a.drop('Adjusted_BoxOffice_Cat',axis = 1)\n",
    "y = data_model4a['Adjusted_BoxOffice_Cat']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3,random_state = 1)\n",
    "\n",
    "\n",
    "svm_clf = svm.SVC(decision_function_shape='ovo')\n",
    "scores = cross_val_score(svm_clf, X_train, y_train, cv=5)\n",
    "\n",
    "svm_clf.fit(X_train, y_train)\n",
    "y_pred = svm_clf.predict(X_test)\n",
    "tst_acc = accuracy_score(y_test, y_pred) * 100\n",
    "cv_acc = np.mean(scores) * 100\n",
    "print('SVM(NLP_SeparatedScore): CV Accuracy: %0.3f | Testing Accuracy: %0.3f' % (cv_acc,tst_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN: CV Accuracy: 31.358 | Testing Accuracy: 32.320\n",
      "KNN(NLP_SeparatedScore): CV Accuracy: 31.312 | Testing Accuracy: 32.642\n"
     ]
    }
   ],
   "source": [
    "#KNN\n",
    "data_model5 = data_model3\n",
    "X = data_model5.drop('Adjusted_BoxOffice_Cat',axis = 1)\n",
    "y = data_model5['Adjusted_BoxOffice_Cat']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3,random_state = 1)\n",
    "\n",
    "neigh = KNeighborsClassifier(n_neighbors=20)\n",
    "scores = cross_val_score(neigh, X_train, y_train, cv=5)\n",
    "\n",
    "neigh.fit(X_train, y_train)\n",
    "y_pred = neigh.predict(X_test)\n",
    "tst_acc = accuracy_score(y_test, y_pred) * 100\n",
    "cv_acc = np.mean(scores) * 100\n",
    "print('KNN: CV Accuracy: %0.3f | Testing Accuracy: %0.3f' % (cv_acc,tst_acc))\n",
    "\n",
    "\n",
    "data_model5a = data_model3a\n",
    "X = data_model5a.drop('Adjusted_BoxOffice_Cat',axis = 1)\n",
    "y = data_model5a['Adjusted_BoxOffice_Cat']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3,random_state = 1)\n",
    "\n",
    "neigh = KNeighborsClassifier(n_neighbors=20)\n",
    "scores = cross_val_score(neigh, X_train, y_train, cv=5)\n",
    "\n",
    "neigh.fit(X_train, y_train)\n",
    "y_pred = neigh.predict(X_test)\n",
    "tst_acc = accuracy_score(y_test, y_pred) * 100\n",
    "cv_acc = np.mean(scores) * 100\n",
    "print('KNN(NLP_SeparatedScore): CV Accuracy: %0.3f | Testing Accuracy: %0.3f' % (cv_acc,tst_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF: CV Accuracy: 36.521 | Testing Accuracy: 38.077\n",
      "RF(NLP_SeparatedScore): CV Accuracy: 38.297 | Testing Accuracy: 38.577\n"
     ]
    }
   ],
   "source": [
    "#Random Forest\n",
    "\n",
    "data_model6 = data_model3\n",
    "X = data_model6.drop('Adjusted_BoxOffice_Cat',axis = 1)\n",
    "y = data_model6['Adjusted_BoxOffice_Cat']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3,random_state = 1)\n",
    "\n",
    "rf_clf = RandomForestClassifier(n_estimators=100, max_depth=8)\n",
    "scores = cross_val_score(rf_clf, X_train, y_train, cv=5)\n",
    "\n",
    "rf_clf.fit(X_train, y_train)\n",
    "y_pred = rf_clf.predict(X_test)\n",
    "tst_acc = accuracy_score(y_test, y_pred) * 100\n",
    "cv_acc = np.mean(scores) * 100\n",
    "print('RF: CV Accuracy: %0.3f | Testing Accuracy: %0.3f' % (cv_acc,tst_acc))\n",
    "\n",
    "\n",
    "data_model6a = data_model3a\n",
    "X = data_model6a.drop('Adjusted_BoxOffice_Cat',axis = 1)\n",
    "y = data_model6a['Adjusted_BoxOffice_Cat']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3,random_state = 1)\n",
    "\n",
    "rf_clf = RandomForestClassifier(n_estimators=100, max_depth=8)\n",
    "scores = cross_val_score(rf_clf, X_train, y_train, cv=5)\n",
    "\n",
    "rf_clf.fit(X_train, y_train)\n",
    "y_pred = rf_clf.predict(X_test)\n",
    "tst_acc = accuracy_score(y_test, y_pred) * 100\n",
    "cv_acc = np.mean(scores) * 100\n",
    "print('RF(NLP_SeparatedScore): CV Accuracy: %0.3f | Testing Accuracy: %0.3f' % (cv_acc,tst_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "6525/6525 [==============================] - 1s 111us/step - loss: 1.9553 - acc: 0.2193\n",
      "Epoch 2/100\n",
      "6525/6525 [==============================] - 0s 51us/step - loss: 1.7570 - acc: 0.2932\n",
      "Epoch 3/100\n",
      "6525/6525 [==============================] - 0s 51us/step - loss: 1.6533 - acc: 0.3269\n",
      "Epoch 4/100\n",
      "6525/6525 [==============================] - 0s 51us/step - loss: 1.5941 - acc: 0.3473\n",
      "Epoch 5/100\n",
      "6525/6525 [==============================] - 0s 52us/step - loss: 1.5589 - acc: 0.3580\n",
      "Epoch 6/100\n",
      "6525/6525 [==============================] - 0s 52us/step - loss: 1.5395 - acc: 0.3664\n",
      "Epoch 7/100\n",
      "6525/6525 [==============================] - 0s 61us/step - loss: 1.5245 - acc: 0.3744\n",
      "Epoch 8/100\n",
      "6525/6525 [==============================] - 0s 59us/step - loss: 1.5152 - acc: 0.3787\n",
      "Epoch 9/100\n",
      "6525/6525 [==============================] - 0s 58us/step - loss: 1.5080 - acc: 0.3767\n",
      "Epoch 10/100\n",
      "6525/6525 [==============================] - 0s 52us/step - loss: 1.5006 - acc: 0.3818\n",
      "Epoch 11/100\n",
      "6525/6525 [==============================] - 0s 54us/step - loss: 1.4955 - acc: 0.3807\n",
      "Epoch 12/100\n",
      "6525/6525 [==============================] - 0s 51us/step - loss: 1.4909 - acc: 0.3838\n",
      "Epoch 13/100\n",
      "6525/6525 [==============================] - 0s 51us/step - loss: 1.4866 - acc: 0.3867\n",
      "Epoch 14/100\n",
      "6525/6525 [==============================] - 0s 51us/step - loss: 1.4826 - acc: 0.3851\n",
      "Epoch 15/100\n",
      "6525/6525 [==============================] - 0s 51us/step - loss: 1.4797 - acc: 0.3887\n",
      "Epoch 16/100\n",
      "6525/6525 [==============================] - 0s 50us/step - loss: 1.4766 - acc: 0.3884\n",
      "Epoch 17/100\n",
      "6525/6525 [==============================] - 0s 68us/step - loss: 1.4741 - acc: 0.3876\n",
      "Epoch 18/100\n",
      "6525/6525 [==============================] - 0s 66us/step - loss: 1.4714 - acc: 0.3874\n",
      "Epoch 19/100\n",
      "6525/6525 [==============================] - 0s 50us/step - loss: 1.4697 - acc: 0.3907\n",
      "Epoch 20/100\n",
      "6525/6525 [==============================] - 0s 53us/step - loss: 1.4667 - acc: 0.3894\n",
      "Epoch 21/100\n",
      "6525/6525 [==============================] - 0s 52us/step - loss: 1.4650 - acc: 0.3930\n",
      "Epoch 22/100\n",
      "6525/6525 [==============================] - 0s 51us/step - loss: 1.4621 - acc: 0.3933\n",
      "Epoch 23/100\n",
      "6525/6525 [==============================] - 0s 52us/step - loss: 1.4606 - acc: 0.3942\n",
      "Epoch 24/100\n",
      "6525/6525 [==============================] - 0s 53us/step - loss: 1.4590 - acc: 0.3945\n",
      "Epoch 25/100\n",
      "6525/6525 [==============================] - 0s 53us/step - loss: 1.4569 - acc: 0.3963\n",
      "Epoch 26/100\n",
      "6525/6525 [==============================] - 0s 68us/step - loss: 1.4553 - acc: 0.3962\n",
      "Epoch 27/100\n",
      "6525/6525 [==============================] - 0s 52us/step - loss: 1.4542 - acc: 0.3949\n",
      "Epoch 28/100\n",
      "6525/6525 [==============================] - 0s 53us/step - loss: 1.4524 - acc: 0.3965\n",
      "Epoch 29/100\n",
      "6525/6525 [==============================] - 0s 51us/step - loss: 1.4507 - acc: 0.3975\n",
      "Epoch 30/100\n",
      "6525/6525 [==============================] - 0s 53us/step - loss: 1.4501 - acc: 0.4014\n",
      "Epoch 31/100\n",
      "6525/6525 [==============================] - 0s 53us/step - loss: 1.4482 - acc: 0.3982\n",
      "Epoch 32/100\n",
      "6525/6525 [==============================] - 0s 52us/step - loss: 1.4465 - acc: 0.3969\n",
      "Epoch 33/100\n",
      "6525/6525 [==============================] - 0s 52us/step - loss: 1.4453 - acc: 0.3980\n",
      "Epoch 34/100\n",
      "6525/6525 [==============================] - 0s 68us/step - loss: 1.4443 - acc: 0.4020\n",
      "Epoch 35/100\n",
      "6525/6525 [==============================] - 0s 69us/step - loss: 1.4433 - acc: 0.3975\n",
      "Epoch 36/100\n",
      "6525/6525 [==============================] - 0s 58us/step - loss: 1.4428 - acc: 0.3994\n",
      "Epoch 37/100\n",
      "6525/6525 [==============================] - 0s 53us/step - loss: 1.4423 - acc: 0.4037\n",
      "Epoch 38/100\n",
      "6525/6525 [==============================] - 0s 57us/step - loss: 1.4412 - acc: 0.4015\n",
      "Epoch 39/100\n",
      "6525/6525 [==============================] - 0s 65us/step - loss: 1.4402 - acc: 0.3992\n",
      "Epoch 40/100\n",
      "6525/6525 [==============================] - 0s 54us/step - loss: 1.4384 - acc: 0.4018\n",
      "Epoch 41/100\n",
      "6525/6525 [==============================] - 0s 64us/step - loss: 1.4383 - acc: 0.3997\n",
      "Epoch 42/100\n",
      "6525/6525 [==============================] - 0s 60us/step - loss: 1.4371 - acc: 0.4009\n",
      "Epoch 43/100\n",
      "6525/6525 [==============================] - 0s 62us/step - loss: 1.4364 - acc: 0.4017\n",
      "Epoch 44/100\n",
      "6525/6525 [==============================] - 0s 59us/step - loss: 1.4361 - acc: 0.4055\n",
      "Epoch 45/100\n",
      "6525/6525 [==============================] - 0s 53us/step - loss: 1.4350 - acc: 0.4055\n",
      "Epoch 46/100\n",
      "6525/6525 [==============================] - 0s 52us/step - loss: 1.4356 - acc: 0.4020\n",
      "Epoch 47/100\n",
      "6525/6525 [==============================] - 0s 54us/step - loss: 1.4339 - acc: 0.4021\n",
      "Epoch 48/100\n",
      "6525/6525 [==============================] - 0s 55us/step - loss: 1.4333 - acc: 0.4057\n",
      "Epoch 49/100\n",
      "6525/6525 [==============================] - 0s 55us/step - loss: 1.4312 - acc: 0.4054\n",
      "Epoch 50/100\n",
      "6525/6525 [==============================] - 0s 54us/step - loss: 1.4306 - acc: 0.4069\n",
      "Epoch 51/100\n",
      "6525/6525 [==============================] - 0s 56us/step - loss: 1.4307 - acc: 0.4023\n",
      "Epoch 52/100\n",
      "6525/6525 [==============================] - 0s 55us/step - loss: 1.4299 - acc: 0.4074\n",
      "Epoch 53/100\n",
      "6525/6525 [==============================] - 0s 57us/step - loss: 1.4288 - acc: 0.4081\n",
      "Epoch 54/100\n",
      "6525/6525 [==============================] - 0s 51us/step - loss: 1.4294 - acc: 0.4038\n",
      "Epoch 55/100\n",
      "6525/6525 [==============================] - 0s 50us/step - loss: 1.4272 - acc: 0.4124\n",
      "Epoch 56/100\n",
      "6525/6525 [==============================] - 0s 67us/step - loss: 1.4274 - acc: 0.4095\n",
      "Epoch 57/100\n",
      "6525/6525 [==============================] - 0s 50us/step - loss: 1.4268 - acc: 0.4101\n",
      "Epoch 58/100\n",
      "6525/6525 [==============================] - 0s 53us/step - loss: 1.4267 - acc: 0.4084\n",
      "Epoch 59/100\n",
      "6525/6525 [==============================] - 0s 52us/step - loss: 1.4252 - acc: 0.4049\n",
      "Epoch 60/100\n",
      "6525/6525 [==============================] - 0s 50us/step - loss: 1.4251 - acc: 0.4121\n",
      "Epoch 61/100\n",
      "6525/6525 [==============================] - 0s 53us/step - loss: 1.4241 - acc: 0.4123\n",
      "Epoch 62/100\n",
      "6525/6525 [==============================] - 0s 51us/step - loss: 1.4231 - acc: 0.4104\n",
      "Epoch 63/100\n",
      "6525/6525 [==============================] - 0s 52us/step - loss: 1.4231 - acc: 0.4104\n",
      "Epoch 64/100\n",
      "6525/6525 [==============================] - 0s 49us/step - loss: 1.4225 - acc: 0.4110\n",
      "Epoch 65/100\n",
      "6525/6525 [==============================] - 0s 50us/step - loss: 1.4227 - acc: 0.4092\n",
      "Epoch 66/100\n",
      "6525/6525 [==============================] - 0s 52us/step - loss: 1.4212 - acc: 0.4139\n",
      "Epoch 67/100\n",
      "6525/6525 [==============================] - 0s 51us/step - loss: 1.4210 - acc: 0.4120\n",
      "Epoch 68/100\n",
      "6525/6525 [==============================] - 0s 51us/step - loss: 1.4213 - acc: 0.4153\n",
      "Epoch 69/100\n",
      "6525/6525 [==============================] - 0s 52us/step - loss: 1.4202 - acc: 0.4130\n",
      "Epoch 70/100\n",
      "6525/6525 [==============================] - 0s 51us/step - loss: 1.4199 - acc: 0.4132\n",
      "Epoch 71/100\n",
      "6525/6525 [==============================] - 0s 53us/step - loss: 1.4191 - acc: 0.4169\n",
      "Epoch 72/100\n",
      "6525/6525 [==============================] - 0s 53us/step - loss: 1.4184 - acc: 0.4141\n",
      "Epoch 73/100\n",
      "6525/6525 [==============================] - 0s 51us/step - loss: 1.4186 - acc: 0.4161\n",
      "Epoch 74/100\n",
      "6525/6525 [==============================] - 0s 50us/step - loss: 1.4185 - acc: 0.4124\n",
      "Epoch 75/100\n",
      "6525/6525 [==============================] - 0s 52us/step - loss: 1.4182 - acc: 0.4132\n",
      "Epoch 76/100\n",
      "6525/6525 [==============================] - 0s 50us/step - loss: 1.4167 - acc: 0.4164\n",
      "Epoch 77/100\n",
      "6525/6525 [==============================] - 0s 51us/step - loss: 1.4165 - acc: 0.4181\n",
      "Epoch 78/100\n",
      "6525/6525 [==============================] - 0s 51us/step - loss: 1.4166 - acc: 0.4127\n",
      "Epoch 79/100\n",
      "6525/6525 [==============================] - 0s 52us/step - loss: 1.4158 - acc: 0.4164\n",
      "Epoch 80/100\n",
      "6525/6525 [==============================] - 0s 56us/step - loss: 1.4159 - acc: 0.4169\n",
      "Epoch 81/100\n",
      "6525/6525 [==============================] - 0s 52us/step - loss: 1.4151 - acc: 0.4166\n",
      "Epoch 82/100\n",
      "6525/6525 [==============================] - 0s 53us/step - loss: 1.4144 - acc: 0.4189\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6525/6525 [==============================] - 0s 50us/step - loss: 1.4145 - acc: 0.4207\n",
      "Epoch 84/100\n",
      "6525/6525 [==============================] - 0s 50us/step - loss: 1.4141 - acc: 0.4146\n",
      "Epoch 85/100\n",
      "6525/6525 [==============================] - 0s 55us/step - loss: 1.4137 - acc: 0.4176\n",
      "Epoch 86/100\n",
      "6525/6525 [==============================] - 0s 53us/step - loss: 1.4125 - acc: 0.4113\n",
      "Epoch 87/100\n",
      "6525/6525 [==============================] - 0s 52us/step - loss: 1.4128 - acc: 0.4138\n",
      "Epoch 88/100\n",
      "6525/6525 [==============================] - 0s 49us/step - loss: 1.4119 - acc: 0.4208\n",
      "Epoch 89/100\n",
      "6525/6525 [==============================] - 0s 48us/step - loss: 1.4120 - acc: 0.4153\n",
      "Epoch 90/100\n",
      "6525/6525 [==============================] - 0s 49us/step - loss: 1.4118 - acc: 0.4172\n",
      "Epoch 91/100\n",
      "6525/6525 [==============================] - 0s 48us/step - loss: 1.4120 - acc: 0.4136\n",
      "Epoch 92/100\n",
      "6525/6525 [==============================] - 0s 51us/step - loss: 1.4110 - acc: 0.4199\n",
      "Epoch 93/100\n",
      "6525/6525 [==============================] - 0s 48us/step - loss: 1.4115 - acc: 0.4144\n",
      "Epoch 94/100\n",
      "6525/6525 [==============================] - 0s 48us/step - loss: 1.4110 - acc: 0.4175\n",
      "Epoch 95/100\n",
      "6525/6525 [==============================] - 0s 49us/step - loss: 1.4097 - acc: 0.4155\n",
      "Epoch 96/100\n",
      "6525/6525 [==============================] - 0s 50us/step - loss: 1.4102 - acc: 0.4201\n",
      "Epoch 97/100\n",
      "6525/6525 [==============================] - 0s 51us/step - loss: 1.4097 - acc: 0.4185\n",
      "Epoch 98/100\n",
      "6525/6525 [==============================] - 0s 59us/step - loss: 1.4089 - acc: 0.4221\n",
      "Epoch 99/100\n",
      "6525/6525 [==============================] - 0s 49us/step - loss: 1.4094 - acc: 0.4156\n",
      "Epoch 100/100\n",
      "6525/6525 [==============================] - 0s 50us/step - loss: 1.4085 - acc: 0.4189\n",
      "NN: Train Accuracy: 0.422 | Testing Accuracy: 0.374\n",
      "Epoch 1/100\n",
      "6525/6525 [==============================] - 1s 110us/step - loss: 2.0142 - acc: 0.2049\n",
      "Epoch 2/100\n",
      "6525/6525 [==============================] - 0s 50us/step - loss: 1.7458 - acc: 0.3160\n",
      "Epoch 3/100\n",
      "6525/6525 [==============================] - 0s 52us/step - loss: 1.6040 - acc: 0.3508\n",
      "Epoch 4/100\n",
      "6525/6525 [==============================] - 0s 51us/step - loss: 1.5560 - acc: 0.3575\n",
      "Epoch 5/100\n",
      "6525/6525 [==============================] - 0s 53us/step - loss: 1.5349 - acc: 0.3615\n",
      "Epoch 6/100\n",
      "6525/6525 [==============================] - 0s 49us/step - loss: 1.5206 - acc: 0.3692\n",
      "Epoch 7/100\n",
      "6525/6525 [==============================] - 0s 50us/step - loss: 1.5104 - acc: 0.3747\n",
      "Epoch 8/100\n",
      "6525/6525 [==============================] - 0s 53us/step - loss: 1.5030 - acc: 0.3713\n",
      "Epoch 9/100\n",
      "6525/6525 [==============================] - 0s 53us/step - loss: 1.4968 - acc: 0.3784\n",
      "Epoch 10/100\n",
      "6525/6525 [==============================] - 0s 52us/step - loss: 1.4906 - acc: 0.3824\n",
      "Epoch 11/100\n",
      "6525/6525 [==============================] - 0s 53us/step - loss: 1.4840 - acc: 0.3874\n",
      "Epoch 12/100\n",
      "6525/6525 [==============================] - 0s 50us/step - loss: 1.4801 - acc: 0.3839\n",
      "Epoch 13/100\n",
      "6525/6525 [==============================] - 0s 53us/step - loss: 1.4753 - acc: 0.3930\n",
      "Epoch 14/100\n",
      "6525/6525 [==============================] - 0s 50us/step - loss: 1.4715 - acc: 0.3913\n",
      "Epoch 15/100\n",
      "6525/6525 [==============================] - 0s 51us/step - loss: 1.4675 - acc: 0.3870\n",
      "Epoch 16/100\n",
      "6525/6525 [==============================] - 0s 52us/step - loss: 1.4641 - acc: 0.3920\n",
      "Epoch 17/100\n",
      "6525/6525 [==============================] - 0s 52us/step - loss: 1.4604 - acc: 0.3946\n",
      "Epoch 18/100\n",
      "6525/6525 [==============================] - 0s 50us/step - loss: 1.4575 - acc: 0.3963\n",
      "Epoch 19/100\n",
      "6525/6525 [==============================] - 0s 51us/step - loss: 1.4546 - acc: 0.4015\n",
      "Epoch 20/100\n",
      "6525/6525 [==============================] - 0s 50us/step - loss: 1.4507 - acc: 0.3986\n",
      "Epoch 21/100\n",
      "6525/6525 [==============================] - 0s 50us/step - loss: 1.4477 - acc: 0.3975\n",
      "Epoch 22/100\n",
      "6525/6525 [==============================] - 0s 52us/step - loss: 1.4449 - acc: 0.4003\n",
      "Epoch 23/100\n",
      "6525/6525 [==============================] - 0s 52us/step - loss: 1.4416 - acc: 0.3989\n",
      "Epoch 24/100\n",
      "6525/6525 [==============================] - 0s 51us/step - loss: 1.4387 - acc: 0.4031\n",
      "Epoch 25/100\n",
      "6525/6525 [==============================] - 0s 50us/step - loss: 1.4363 - acc: 0.4037\n",
      "Epoch 26/100\n",
      "6525/6525 [==============================] - 0s 50us/step - loss: 1.4340 - acc: 0.4037\n",
      "Epoch 27/100\n",
      "6525/6525 [==============================] - 0s 51us/step - loss: 1.4316 - acc: 0.4075\n",
      "Epoch 28/100\n",
      "6525/6525 [==============================] - 0s 52us/step - loss: 1.4301 - acc: 0.4098\n",
      "Epoch 29/100\n",
      "6525/6525 [==============================] - 0s 51us/step - loss: 1.4281 - acc: 0.4100\n",
      "Epoch 30/100\n",
      "6525/6525 [==============================] - 0s 51us/step - loss: 1.4267 - acc: 0.4118\n",
      "Epoch 31/100\n",
      "6525/6525 [==============================] - 0s 52us/step - loss: 1.4250 - acc: 0.4089\n",
      "Epoch 32/100\n",
      "6525/6525 [==============================] - 0s 52us/step - loss: 1.4227 - acc: 0.4061\n",
      "Epoch 33/100\n",
      "6525/6525 [==============================] - 0s 53us/step - loss: 1.4224 - acc: 0.4104\n",
      "Epoch 34/100\n",
      "6525/6525 [==============================] - 0s 51us/step - loss: 1.4201 - acc: 0.4132\n",
      "Epoch 35/100\n",
      "6525/6525 [==============================] - 0s 53us/step - loss: 1.4196 - acc: 0.4132\n",
      "Epoch 36/100\n",
      "6525/6525 [==============================] - 0s 53us/step - loss: 1.4181 - acc: 0.4161\n",
      "Epoch 37/100\n",
      "6525/6525 [==============================] - 0s 53us/step - loss: 1.4173 - acc: 0.4127\n",
      "Epoch 38/100\n",
      "6525/6525 [==============================] - 0s 52us/step - loss: 1.4157 - acc: 0.4144\n",
      "Epoch 39/100\n",
      "6525/6525 [==============================] - 0s 50us/step - loss: 1.4148 - acc: 0.4121\n",
      "Epoch 40/100\n",
      "6525/6525 [==============================] - 0s 52us/step - loss: 1.4133 - acc: 0.4118\n",
      "Epoch 41/100\n",
      "6525/6525 [==============================] - 0s 51us/step - loss: 1.4134 - acc: 0.4153\n",
      "Epoch 42/100\n",
      "6525/6525 [==============================] - 0s 51us/step - loss: 1.4116 - acc: 0.4172\n",
      "Epoch 43/100\n",
      "6525/6525 [==============================] - 0s 51us/step - loss: 1.4107 - acc: 0.4172\n",
      "Epoch 44/100\n",
      "6525/6525 [==============================] - 0s 51us/step - loss: 1.4096 - acc: 0.4136\n",
      "Epoch 45/100\n",
      "6525/6525 [==============================] - 0s 53us/step - loss: 1.4092 - acc: 0.4152\n",
      "Epoch 46/100\n",
      "6525/6525 [==============================] - 0s 51us/step - loss: 1.4073 - acc: 0.4169\n",
      "Epoch 47/100\n",
      "6525/6525 [==============================] - 0s 51us/step - loss: 1.4075 - acc: 0.4155\n",
      "Epoch 48/100\n",
      "6525/6525 [==============================] - 0s 52us/step - loss: 1.4061 - acc: 0.4135\n",
      "Epoch 49/100\n",
      "6525/6525 [==============================] - 0s 57us/step - loss: 1.4052 - acc: 0.4147\n",
      "Epoch 50/100\n",
      "6525/6525 [==============================] - 0s 52us/step - loss: 1.4039 - acc: 0.4199\n",
      "Epoch 51/100\n",
      "6525/6525 [==============================] - 0s 52us/step - loss: 1.4046 - acc: 0.4139\n",
      "Epoch 52/100\n",
      "6525/6525 [==============================] - 0s 53us/step - loss: 1.4033 - acc: 0.4159\n",
      "Epoch 53/100\n",
      "6525/6525 [==============================] - 0s 50us/step - loss: 1.4026 - acc: 0.4190\n",
      "Epoch 54/100\n",
      "6525/6525 [==============================] - 0s 52us/step - loss: 1.4019 - acc: 0.4172\n",
      "Epoch 55/100\n",
      "6525/6525 [==============================] - 0s 52us/step - loss: 1.4007 - acc: 0.4162\n",
      "Epoch 56/100\n",
      "6525/6525 [==============================] - 0s 53us/step - loss: 1.4005 - acc: 0.4170\n",
      "Epoch 57/100\n",
      "6525/6525 [==============================] - 0s 51us/step - loss: 1.3986 - acc: 0.4190\n",
      "Epoch 58/100\n",
      "6525/6525 [==============================] - 0s 55us/step - loss: 1.3990 - acc: 0.4159\n",
      "Epoch 59/100\n",
      "6525/6525 [==============================] - 0s 52us/step - loss: 1.3989 - acc: 0.4143\n",
      "Epoch 60/100\n",
      "6525/6525 [==============================] - 0s 51us/step - loss: 1.3971 - acc: 0.4189\n",
      "Epoch 61/100\n",
      "6525/6525 [==============================] - 0s 54us/step - loss: 1.3979 - acc: 0.4162\n",
      "Epoch 62/100\n",
      "6525/6525 [==============================] - 0s 53us/step - loss: 1.3963 - acc: 0.4181\n",
      "Epoch 63/100\n",
      "6525/6525 [==============================] - 0s 52us/step - loss: 1.3959 - acc: 0.4207\n",
      "Epoch 64/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6525/6525 [==============================] - 0s 52us/step - loss: 1.3949 - acc: 0.4169\n",
      "Epoch 65/100\n",
      "6525/6525 [==============================] - 0s 49us/step - loss: 1.3941 - acc: 0.4205\n",
      "Epoch 66/100\n",
      "6525/6525 [==============================] - 0s 49us/step - loss: 1.3949 - acc: 0.4192\n",
      "Epoch 67/100\n",
      "6525/6525 [==============================] - 0s 52us/step - loss: 1.3931 - acc: 0.4193\n",
      "Epoch 68/100\n",
      "6525/6525 [==============================] - 0s 49us/step - loss: 1.3925 - acc: 0.4164\n",
      "Epoch 69/100\n",
      "6525/6525 [==============================] - 0s 50us/step - loss: 1.3933 - acc: 0.4181\n",
      "Epoch 70/100\n",
      "6525/6525 [==============================] - 0s 49us/step - loss: 1.3917 - acc: 0.4208\n",
      "Epoch 71/100\n",
      "6525/6525 [==============================] - 0s 49us/step - loss: 1.3915 - acc: 0.4185\n",
      "Epoch 72/100\n",
      "6525/6525 [==============================] - 0s 48us/step - loss: 1.3910 - acc: 0.4199\n",
      "Epoch 73/100\n",
      "6525/6525 [==============================] - 0s 49us/step - loss: 1.3895 - acc: 0.4182\n",
      "Epoch 74/100\n",
      "6525/6525 [==============================] - 0s 51us/step - loss: 1.3899 - acc: 0.4181\n",
      "Epoch 75/100\n",
      "6525/6525 [==============================] - 0s 51us/step - loss: 1.3897 - acc: 0.4219\n",
      "Epoch 76/100\n",
      "6525/6525 [==============================] - 0s 51us/step - loss: 1.3886 - acc: 0.4192\n",
      "Epoch 77/100\n",
      "6525/6525 [==============================] - 0s 50us/step - loss: 1.3870 - acc: 0.4216\n",
      "Epoch 78/100\n",
      "6525/6525 [==============================] - 0s 50us/step - loss: 1.3861 - acc: 0.4187\n",
      "Epoch 79/100\n",
      "6525/6525 [==============================] - 0s 51us/step - loss: 1.3865 - acc: 0.4185\n",
      "Epoch 80/100\n",
      "6525/6525 [==============================] - 0s 52us/step - loss: 1.3867 - acc: 0.4181\n",
      "Epoch 81/100\n",
      "6525/6525 [==============================] - 0s 50us/step - loss: 1.3853 - acc: 0.4216\n",
      "Epoch 82/100\n",
      "6525/6525 [==============================] - 0s 58us/step - loss: 1.3848 - acc: 0.4193\n",
      "Epoch 83/100\n",
      "6525/6525 [==============================] - 0s 50us/step - loss: 1.3837 - acc: 0.4230\n",
      "Epoch 84/100\n",
      "6525/6525 [==============================] - 0s 50us/step - loss: 1.3839 - acc: 0.4190\n",
      "Epoch 85/100\n",
      "6525/6525 [==============================] - 0s 56us/step - loss: 1.3831 - acc: 0.4219\n",
      "Epoch 86/100\n",
      "6525/6525 [==============================] - 0s 49us/step - loss: 1.3821 - acc: 0.4208\n",
      "Epoch 87/100\n",
      "6525/6525 [==============================] - 0s 48us/step - loss: 1.3814 - acc: 0.4218\n",
      "Epoch 88/100\n",
      "6525/6525 [==============================] - 0s 53us/step - loss: 1.3811 - acc: 0.4215\n",
      "Epoch 89/100\n",
      "6525/6525 [==============================] - 0s 49us/step - loss: 1.3807 - acc: 0.4219\n",
      "Epoch 90/100\n",
      "6525/6525 [==============================] - 0s 50us/step - loss: 1.3801 - acc: 0.4224\n",
      "Epoch 91/100\n",
      "6525/6525 [==============================] - 0s 50us/step - loss: 1.3796 - acc: 0.4172\n",
      "Epoch 92/100\n",
      "6525/6525 [==============================] - 0s 50us/step - loss: 1.3793 - acc: 0.4236\n",
      "Epoch 93/100\n",
      "6525/6525 [==============================] - 0s 50us/step - loss: 1.3788 - acc: 0.4225\n",
      "Epoch 94/100\n",
      "6525/6525 [==============================] - 0s 52us/step - loss: 1.3781 - acc: 0.4221\n",
      "Epoch 95/100\n",
      "6525/6525 [==============================] - 0s 52us/step - loss: 1.3781 - acc: 0.4247\n",
      "Epoch 96/100\n",
      "6525/6525 [==============================] - 0s 54us/step - loss: 1.3777 - acc: 0.4227\n",
      "Epoch 97/100\n",
      "6525/6525 [==============================] - 0s 51us/step - loss: 1.3769 - acc: 0.4262\n",
      "Epoch 98/100\n",
      "6525/6525 [==============================] - 0s 51us/step - loss: 1.3776 - acc: 0.4204\n",
      "Epoch 99/100\n",
      "6525/6525 [==============================] - 0s 53us/step - loss: 1.3767 - acc: 0.4251\n",
      "Epoch 100/100\n",
      "6525/6525 [==============================] - 0s 51us/step - loss: 1.3756 - acc: 0.4239\n",
      "NN(NLP_SeparatedScore): Train Accuracy: 0.430 | Testing Accuracy: 0.384\n"
     ]
    }
   ],
   "source": [
    "def one_hot_encoding(y):\n",
    "    encoder = LabelEncoder()\n",
    "    encoder.fit(y)\n",
    "    encoded_y = encoder.transform(y)\n",
    "    dummy_y = np_utils.to_categorical(encoded_y)\n",
    "    return (dummy_y)\n",
    "\n",
    "data_nn = data_model3\n",
    "\n",
    "X = data_nn.drop('Adjusted_BoxOffice_Cat',axis = 1)\n",
    "y = data_nn['Adjusted_BoxOffice_Cat']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3,random_state = 1)\n",
    "\n",
    "dummy_y_train = one_hot_encoding(y_train)\n",
    "\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(16, input_dim=data_nn.shape[1]-1, activation='relu'))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(len(all_cats), activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(X_train, dummy_y_train, batch_size = 50, epochs = 100)\n",
    "\n",
    "predictions = model.predict_classes(X_test)\n",
    "y_pred = np.argmax(np_utils.to_categorical(predictions), axis = 1)\n",
    "\n",
    "train_predictions = model.predict_classes(X_train)\n",
    "train_y_pred = np.argmax(np_utils.to_categorical(train_predictions), axis = 1)\n",
    "\n",
    "tst_acc = accuracy_score(y_test, y_pred)\n",
    "tr_acc = accuracy_score(y_train, train_y_pred)\n",
    "print('NN: Train Accuracy: %0.3f | Testing Accuracy: %0.3f' % (tr_acc,tst_acc))\n",
    "\n",
    "\n",
    "\n",
    "data_nna = data_model3a\n",
    "\n",
    "X = data_nna.drop('Adjusted_BoxOffice_Cat',axis = 1)\n",
    "y = data_nna['Adjusted_BoxOffice_Cat']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3,random_state = 1)\n",
    "\n",
    "dummy_y_train = one_hot_encoding(y_train)\n",
    "\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(16, input_dim=data_nna.shape[1]-1, activation='relu'))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(len(all_cats), activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(X_train, dummy_y_train, batch_size = 50, epochs = 100)\n",
    "\n",
    "predictions = model.predict_classes(X_test)\n",
    "y_pred = np.argmax(np_utils.to_categorical(predictions), axis = 1)\n",
    "\n",
    "train_predictions = model.predict_classes(X_train)\n",
    "train_y_pred = np.argmax(np_utils.to_categorical(train_predictions), axis = 1)\n",
    "\n",
    "tst_acc = accuracy_score(y_test, y_pred)\n",
    "tr_acc = accuracy_score(y_train, train_y_pred)\n",
    "print('NN(NLP_SeparatedScore): Train Accuracy: %0.3f | Testing Accuracy: %0.3f' % (tr_acc,tst_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wwengm/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Adjusted_BoxOffice</th>\n",
       "      <th>BoxOffice</th>\n",
       "      <th>NLP_Score</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Year</th>\n",
       "      <th>imdbRating</th>\n",
       "      <th>imdbVotes</th>\n",
       "      <th>Internet_Movie_Database</th>\n",
       "      <th>Rotten_Tomatoes</th>\n",
       "      <th>...</th>\n",
       "      <th>War</th>\n",
       "      <th>Western</th>\n",
       "      <th>Country_count</th>\n",
       "      <th>budget</th>\n",
       "      <th>Adjusted_Budgets</th>\n",
       "      <th>Director_Score</th>\n",
       "      <th>Writer_Score</th>\n",
       "      <th>Actor_Score</th>\n",
       "      <th>Adjusted_BoxOffice_Cat</th>\n",
       "      <th>log_Adjusted_Budgets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3428.000000</td>\n",
       "      <td>3428.000000</td>\n",
       "      <td>3428.000000</td>\n",
       "      <td>3428.000000</td>\n",
       "      <td>3428.000000</td>\n",
       "      <td>3428.000000</td>\n",
       "      <td>3428.000000</td>\n",
       "      <td>3.428000e+03</td>\n",
       "      <td>3428.000000</td>\n",
       "      <td>3428.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3428.000000</td>\n",
       "      <td>3428.000000</td>\n",
       "      <td>3428.000000</td>\n",
       "      <td>3.428000e+03</td>\n",
       "      <td>3428.000000</td>\n",
       "      <td>3428.000000</td>\n",
       "      <td>3428.000000</td>\n",
       "      <td>3428.000000</td>\n",
       "      <td>3428.000000</td>\n",
       "      <td>3428.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3804.012835</td>\n",
       "      <td>61.228251</td>\n",
       "      <td>48.081917</td>\n",
       "      <td>11.762070</td>\n",
       "      <td>107.611435</td>\n",
       "      <td>2006.094807</td>\n",
       "      <td>6.404259</td>\n",
       "      <td>1.103732e+05</td>\n",
       "      <td>6.404259</td>\n",
       "      <td>5.317272</td>\n",
       "      <td>...</td>\n",
       "      <td>0.031505</td>\n",
       "      <td>0.012252</td>\n",
       "      <td>1.567970</td>\n",
       "      <td>3.833468e+07</td>\n",
       "      <td>48.302463</td>\n",
       "      <td>1.714490</td>\n",
       "      <td>0.873312</td>\n",
       "      <td>9.174269</td>\n",
       "      <td>2.403442</td>\n",
       "      <td>3.129973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2501.695798</td>\n",
       "      <td>86.387795</td>\n",
       "      <td>69.499904</td>\n",
       "      <td>5.321263</td>\n",
       "      <td>18.158049</td>\n",
       "      <td>6.760831</td>\n",
       "      <td>1.006750</td>\n",
       "      <td>1.702775e+05</td>\n",
       "      <td>1.006750</td>\n",
       "      <td>2.710814</td>\n",
       "      <td>...</td>\n",
       "      <td>0.174704</td>\n",
       "      <td>0.110025</td>\n",
       "      <td>0.963768</td>\n",
       "      <td>4.505118e+07</td>\n",
       "      <td>53.827954</td>\n",
       "      <td>1.184290</td>\n",
       "      <td>0.700502</td>\n",
       "      <td>4.642016</td>\n",
       "      <td>1.296787</td>\n",
       "      <td>1.527367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000528</td>\n",
       "      <td>0.000423</td>\n",
       "      <td>1.429214</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>1990.000000</td>\n",
       "      <td>1.900000</td>\n",
       "      <td>4.000000e+01</td>\n",
       "      <td>1.900000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000e+03</td>\n",
       "      <td>0.009063</td>\n",
       "      <td>0.045814</td>\n",
       "      <td>0.022431</td>\n",
       "      <td>0.742888</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-4.703546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2078.750000</td>\n",
       "      <td>6.298624</td>\n",
       "      <td>4.781412</td>\n",
       "      <td>7.635184</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>2001.000000</td>\n",
       "      <td>5.800000</td>\n",
       "      <td>1.691225e+04</td>\n",
       "      <td>5.800000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.200000e+06</td>\n",
       "      <td>11.353044</td>\n",
       "      <td>0.791108</td>\n",
       "      <td>0.373012</td>\n",
       "      <td>5.552175</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.429481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3355.000000</td>\n",
       "      <td>31.483658</td>\n",
       "      <td>24.576919</td>\n",
       "      <td>11.581251</td>\n",
       "      <td>104.000000</td>\n",
       "      <td>2006.000000</td>\n",
       "      <td>6.500000</td>\n",
       "      <td>5.235550e+04</td>\n",
       "      <td>6.500000</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.400000e+07</td>\n",
       "      <td>29.612011</td>\n",
       "      <td>1.444708</td>\n",
       "      <td>0.663881</td>\n",
       "      <td>9.005369</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.388176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5228.500000</td>\n",
       "      <td>78.414700</td>\n",
       "      <td>60.600000</td>\n",
       "      <td>15.530408</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>2012.000000</td>\n",
       "      <td>7.100000</td>\n",
       "      <td>1.286035e+05</td>\n",
       "      <td>7.100000</td>\n",
       "      <td>7.700000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>5.000000e+07</td>\n",
       "      <td>66.110107</td>\n",
       "      <td>2.361660</td>\n",
       "      <td>1.150673</td>\n",
       "      <td>12.605363</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.191322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>11104.000000</td>\n",
       "      <td>1039.048028</td>\n",
       "      <td>749.700000</td>\n",
       "      <td>28.108077</td>\n",
       "      <td>194.000000</td>\n",
       "      <td>2018.000000</td>\n",
       "      <td>9.300000</td>\n",
       "      <td>2.018482e+06</td>\n",
       "      <td>9.300000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>4.250000e+08</td>\n",
       "      <td>501.035781</td>\n",
       "      <td>6.481680</td>\n",
       "      <td>5.620875</td>\n",
       "      <td>21.915807</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>6.216678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Unnamed: 0  Adjusted_BoxOffice    BoxOffice    NLP_Score  \\\n",
       "count   3428.000000         3428.000000  3428.000000  3428.000000   \n",
       "mean    3804.012835           61.228251    48.081917    11.762070   \n",
       "std     2501.695798           86.387795    69.499904     5.321263   \n",
       "min        0.000000            0.000528     0.000423     1.429214   \n",
       "25%     2078.750000            6.298624     4.781412     7.635184   \n",
       "50%     3355.000000           31.483658    24.576919    11.581251   \n",
       "75%     5228.500000           78.414700    60.600000    15.530408   \n",
       "max    11104.000000         1039.048028   749.700000    28.108077   \n",
       "\n",
       "           Runtime         Year   imdbRating     imdbVotes  \\\n",
       "count  3428.000000  3428.000000  3428.000000  3.428000e+03   \n",
       "mean    107.611435  2006.094807     6.404259  1.103732e+05   \n",
       "std      18.158049     6.760831     1.006750  1.702775e+05   \n",
       "min      59.000000  1990.000000     1.900000  4.000000e+01   \n",
       "25%      95.000000  2001.000000     5.800000  1.691225e+04   \n",
       "50%     104.000000  2006.000000     6.500000  5.235550e+04   \n",
       "75%     117.000000  2012.000000     7.100000  1.286035e+05   \n",
       "max     194.000000  2018.000000     9.300000  2.018482e+06   \n",
       "\n",
       "       Internet_Movie_Database  Rotten_Tomatoes          ...           \\\n",
       "count              3428.000000      3428.000000          ...            \n",
       "mean                  6.404259         5.317272          ...            \n",
       "std                   1.006750         2.710814          ...            \n",
       "min                   1.900000         0.000000          ...            \n",
       "25%                   5.800000         3.000000          ...            \n",
       "50%                   6.500000         5.500000          ...            \n",
       "75%                   7.100000         7.700000          ...            \n",
       "max                   9.300000        10.000000          ...            \n",
       "\n",
       "               War      Western  Country_count        budget  \\\n",
       "count  3428.000000  3428.000000    3428.000000  3.428000e+03   \n",
       "mean      0.031505     0.012252       1.567970  3.833468e+07   \n",
       "std       0.174704     0.110025       0.963768  4.505118e+07   \n",
       "min       0.000000     0.000000       1.000000  6.000000e+03   \n",
       "25%       0.000000     0.000000       1.000000  9.200000e+06   \n",
       "50%       0.000000     0.000000       1.000000  2.400000e+07   \n",
       "75%       0.000000     0.000000       2.000000  5.000000e+07   \n",
       "max       1.000000     1.000000      16.000000  4.250000e+08   \n",
       "\n",
       "       Adjusted_Budgets  Director_Score  Writer_Score  Actor_Score  \\\n",
       "count       3428.000000     3428.000000   3428.000000  3428.000000   \n",
       "mean          48.302463        1.714490      0.873312     9.174269   \n",
       "std           53.827954        1.184290      0.700502     4.642016   \n",
       "min            0.009063        0.045814      0.022431     0.742888   \n",
       "25%           11.353044        0.791108      0.373012     5.552175   \n",
       "50%           29.612011        1.444708      0.663881     9.005369   \n",
       "75%           66.110107        2.361660      1.150673    12.605363   \n",
       "max          501.035781        6.481680      5.620875    21.915807   \n",
       "\n",
       "       Adjusted_BoxOffice_Cat  log_Adjusted_Budgets  \n",
       "count             3428.000000           3428.000000  \n",
       "mean                 2.403442              3.129973  \n",
       "std                  1.296787              1.527367  \n",
       "min                  0.000000             -4.703546  \n",
       "25%                  1.000000              2.429481  \n",
       "50%                  3.000000              3.388176  \n",
       "75%                  3.000000              4.191322  \n",
       "max                  7.000000              6.216678  \n",
       "\n",
       "[8 rows x 43 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_budget = data[data.Adjusted_Budgets.notna()]\n",
    "data_budget['log_Adjusted_Budgets'] = np.log(data_budget['Adjusted_Budgets'] )\n",
    "data_budget.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wwengm/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n",
      "/home/wwengm/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f48d86dba58>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "log_boxoffice = np.log(data_budget['Adjusted_BoxOffice'])\n",
    "cat_raw = pd.cut(log_boxoffice, [-10,-6,-4,-2,0,2,4,6,10])\n",
    "all_cats = cat_raw.unique()\n",
    "cat_encoder = dict([(i,x) for x,i in enumerate(all_cats)])\n",
    "data_budget['Adjusted_BoxOffice_Cat'] = cat_raw.replace(cat_encoder)\n",
    "data_budget['Adjusted_BoxOffice_Cat'].hist()\n",
    "\n",
    "log_Adjusted_Budgets = np.log(data_budget['Adjusted_Budgets'])\n",
    "cat_raw = pd.cut(log_Adjusted_Budgets, [-10,-6,-4,-2,0,2,4,6,10])\n",
    "all_cats = cat_raw.unique()\n",
    "cat_encoder = dict([(i,x) for x,i in enumerate(all_cats)])\n",
    "data_budget['Adjusted_Budgets_Cat'] = cat_raw.replace(cat_encoder)\n",
    "data_budget['Adjusted_Budgets_Cat'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forest with budget Cat\n",
    "\n",
    "# data_model7 = data_budget[['Adjusted_BoxOffice_Cat', 'Runtime','Year', 'imdbRating', 'imdbVotes',\n",
    "#        'Internet_Movie_Database', 'Rotten_Tomatoes', 'Metacritic',\n",
    "#        'Action','Adventure', 'Animation', 'Biography', 'Comedy', 'Crime', 'Documentary',\n",
    "#        'Drama', 'Family', 'Fantasy', 'Film-Noir', 'History', 'Horror', 'Music',\n",
    "#        'Musical', 'Mystery', 'News', 'Romance', 'Sci-Fi', 'Short', 'Sport',\n",
    "#        'Thriller', 'War', 'Western', 'Country_count','NLP_Score','Adjusted_Budgets_Cat']]\n",
    "\n",
    "# X = data_model7.drop('Adjusted_BoxOffice_Cat',axis = 1)\n",
    "# y = data_model7['Adjusted_BoxOffice_Cat']\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3,random_state = 1)\n",
    "\n",
    "# rf_clf = RandomForestClassifier(n_estimators=100, max_depth=8)\n",
    "# scores = cross_val_score(rf_clf, X_train, y_train, cv=5)\n",
    "\n",
    "# rf_clf.fit(X_train, y_train)\n",
    "# y_pred = rf_clf.predict(X_test)\n",
    "# tst_acc = accuracy_score(y_test, y_pred) * 100\n",
    "# cv_acc = np.mean(scores) * 100\n",
    "# print('RF2: CV Accuracy: %0.3f | Testing Accuracy: %0.3f' % (cv_acc,tst_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_model7 = data_budget[['Adjusted_BoxOffice_Cat', 'Runtime','Year', 'imdbRating', 'imdbVotes',\n",
    "#        'Internet_Movie_Database', 'Rotten_Tomatoes', 'Metacritic',\n",
    "#        'Action','Adventure', 'Animation', 'Biography', 'Comedy', 'Crime', 'Documentary',\n",
    "#        'Drama', 'Family', 'Fantasy', 'Film-Noir', 'History', 'Horror', 'Music',\n",
    "#        'Musical', 'Mystery', 'News', 'Romance', 'Sci-Fi', 'Short', 'Sport',\n",
    "#        'Thriller', 'War', 'Western', 'Country_count','NLP_Score']]\n",
    "\n",
    "# X = data_model7.drop('Adjusted_BoxOffice_Cat',axis = 1)\n",
    "# y = data_model7['Adjusted_BoxOffice_Cat']\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3,random_state = 1)\n",
    "\n",
    "# rf_clf = RandomForestClassifier(n_estimators=100, max_depth=8)\n",
    "# scores = cross_val_score(rf_clf, X_train, y_train, cv=5)\n",
    "\n",
    "# rf_clf.fit(X_train, y_train)\n",
    "# y_pred = rf_clf.predict(X_test)\n",
    "# tst_acc = accuracy_score(y_test, y_pred) * 100\n",
    "# cv_acc = np.mean(scores) * 100\n",
    "# print('RF2: CV Accuracy: %0.3f | Testing Accuracy: %0.3f' % (cv_acc,tst_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              OLS Regression Results                              \n",
      "==================================================================================\n",
      "Dep. Variable:     log_Adjusted_BoxOffice   R-squared:                       0.503\n",
      "Model:                                OLS   Adj. R-squared:                  0.497\n",
      "Method:                     Least Squares   F-statistic:                     95.89\n",
      "Date:                    Wed, 05 Dec 2018   Prob (F-statistic):               0.00\n",
      "Time:                            00:10:32   Log-Likelihood:                -4739.7\n",
      "No. Observations:                    2399   AIC:                             9531.\n",
      "Df Residuals:                        2373   BIC:                             9682.\n",
      "Df Model:                              25                                         \n",
      "Covariance Type:                nonrobust                                         \n",
      "========================================================================================\n",
      "                           coef    std err          t      P>|t|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------------\n",
      "const                   -1.9421      0.279     -6.966      0.000      -2.489      -1.395\n",
      "Runtime                  0.0142      0.003      5.553      0.000       0.009       0.019\n",
      "Action                  -0.0526      0.108     -0.486      0.627      -0.265       0.160\n",
      "Adventure                0.1112      0.116      0.956      0.339      -0.117       0.339\n",
      "Animation                0.0963      0.206      0.468      0.640      -0.307       0.500\n",
      "Biography                0.2427      0.160      1.519      0.129      -0.071       0.556\n",
      "Comedy                   0.2944      0.098      2.999      0.003       0.102       0.487\n",
      "Crime                   -0.1763      0.104     -1.701      0.089      -0.379       0.027\n",
      "Documentary              0.0032      0.334      0.010      0.992      -0.651       0.657\n",
      "Drama                   -0.2541      0.095     -2.687      0.007      -0.439      -0.069\n",
      "Family                   0.4554      0.153      2.967      0.003       0.154       0.756\n",
      "Fantasy                 -0.0976      0.128     -0.763      0.445      -0.349       0.153\n",
      "Film-Noir             5.745e-17   1.56e-16      0.367      0.713   -2.49e-16    3.64e-16\n",
      "History                 -0.1537      0.216     -0.712      0.476      -0.577       0.269\n",
      "Horror                   0.4135      0.140      2.963      0.003       0.140       0.687\n",
      "Music                    0.3152      0.184      1.711      0.087      -0.046       0.676\n",
      "Musical                 -0.2840      0.273     -1.040      0.298      -0.819       0.251\n",
      "Mystery                  0.4130      0.125      3.299      0.001       0.168       0.658\n",
      "News                     0.0636      1.788      0.036      0.972      -3.442       3.569\n",
      "Romance                  0.2495      0.094      2.647      0.008       0.065       0.434\n",
      "Sci-Fi                  -0.1303      0.125     -1.042      0.298      -0.376       0.115\n",
      "Short                -2.067e-16   3.51e-16     -0.588      0.556   -8.96e-16    4.82e-16\n",
      "Sport                   -0.0285      0.205     -0.139      0.890      -0.431       0.374\n",
      "Thriller                 0.2180      0.102      2.142      0.032       0.018       0.418\n",
      "War                     -0.2920      0.216     -1.351      0.177      -0.716       0.132\n",
      "Western                 -0.6466      0.344     -1.881      0.060      -1.321       0.028\n",
      "Country_count           -0.1986      0.040     -5.018      0.000      -0.276      -0.121\n",
      "log_Adjusted_Budgets     1.0382      0.030     34.343      0.000       0.979       1.097\n",
      "==============================================================================\n",
      "Omnibus:                      520.256   Durbin-Watson:                   1.966\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             1377.476\n",
      "Skew:                          -1.149   Prob(JB):                    7.67e-300\n",
      "Kurtosis:                       5.915   Cond. No.                     1.02e+16\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The smallest eigenvalue is 2.76e-25. This might indicate that there are\n",
      "strong multicollinearity problems or that the design matrix is singular.\n",
      "Out of Sample R2 is : 0.483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wwengm/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/home/wwengm/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "data_budget['log_Adjusted_Budgets'] = np.log(data_budget['Adjusted_Budgets'] )\n",
    "data_budget['log_Adjusted_BoxOffice'] = np.log(data_budget['Adjusted_BoxOffice'] )\n",
    "\n",
    "#Baseline Model: A simple Regression\n",
    "\n",
    "data_model8 = data_budget[['log_Adjusted_BoxOffice', 'Runtime',\n",
    "        'Action','Adventure', 'Animation', 'Biography', 'Comedy', 'Crime', 'Documentary',\n",
    "       'Drama', 'Family', 'Fantasy', 'Film-Noir', 'History', 'Horror', 'Music',\n",
    "       'Musical', 'Mystery', 'News', 'Romance', 'Sci-Fi', 'Short', 'Sport',\n",
    "       'Thriller', 'War', 'Western', 'Country_count','log_Adjusted_Budgets']]\n",
    "\n",
    "X = data_model8.drop('log_Adjusted_BoxOffice',axis = 1)\n",
    "y = data_model8['log_Adjusted_BoxOffice']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3,random_state = 1)\n",
    "\n",
    "\n",
    "lr_model1 = sm.OLS(y_train, sm.add_constant(X_train))\n",
    "lr_est1 = lr_model1.fit()\n",
    "print(lr_est1.summary())\n",
    "\n",
    "# Out of Sample\n",
    "pred = lr_est1.predict(sm.add_constant(X_test))\n",
    "oosr = 1 - sum([x*x for x in (pred-y_test)])/sum([x*x for x in (sum(y_train)/len(y_train)-y_test)])\n",
    "print('Out of Sample R2 is : %s' %round(oosr,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              OLS Regression Results                              \n",
      "==================================================================================\n",
      "Dep. Variable:     log_Adjusted_BoxOffice   R-squared:                       0.507\n",
      "Model:                                OLS   Adj. R-squared:                  0.502\n",
      "Method:                     Least Squares   F-statistic:                     94.01\n",
      "Date:                    Wed, 05 Dec 2018   Prob (F-statistic):               0.00\n",
      "Time:                            00:10:32   Log-Likelihood:                -4727.7\n",
      "No. Observations:                    2399   AIC:                             9509.\n",
      "Df Residuals:                        2372   BIC:                             9666.\n",
      "Df Model:                              26                                         \n",
      "Covariance Type:                nonrobust                                         \n",
      "========================================================================================\n",
      "                           coef    std err          t      P>|t|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------------\n",
      "const                   -2.0040      0.278     -7.215      0.000      -2.549      -1.459\n",
      "Runtime                  0.0124      0.003      4.830      0.000       0.007       0.017\n",
      "Action                  -0.0168      0.108     -0.156      0.876      -0.228       0.195\n",
      "Adventure                0.1461      0.116      1.260      0.208      -0.081       0.374\n",
      "Animation                0.0692      0.205      0.338      0.736      -0.333       0.471\n",
      "Biography                0.2217      0.159      1.394      0.163      -0.090       0.534\n",
      "Comedy                   0.2844      0.098      2.910      0.004       0.093       0.476\n",
      "Crime                   -0.2038      0.103     -1.974      0.049      -0.406      -0.001\n",
      "Documentary              0.0859      0.332      0.258      0.796      -0.566       0.738\n",
      "Drama                   -0.2989      0.095     -3.161      0.002      -0.484      -0.114\n",
      "Family                   0.5192      0.153      3.387      0.001       0.219       0.820\n",
      "Fantasy                 -0.0823      0.127     -0.646      0.518      -0.332       0.168\n",
      "Film-Noir              4.75e-16   2.92e-15      0.163      0.871   -5.25e-15     6.2e-15\n",
      "History                 -0.1005      0.215     -0.467      0.640      -0.522       0.321\n",
      "Horror                   0.5057      0.140      3.608      0.000       0.231       0.781\n",
      "Music                    0.3971      0.184      2.157      0.031       0.036       0.758\n",
      "Musical                 -0.2274      0.272     -0.836      0.403      -0.761       0.306\n",
      "Mystery                  0.3997      0.125      3.208      0.001       0.155       0.644\n",
      "News                     0.2583      1.780      0.145      0.885      -3.231       3.748\n",
      "Romance                  0.2465      0.094      2.628      0.009       0.063       0.430\n",
      "Sci-Fi                  -0.1297      0.124     -1.042      0.297      -0.374       0.114\n",
      "Short                  4.97e-17   4.19e-16      0.119      0.906   -7.73e-16    8.72e-16\n",
      "Sport                    0.0202      0.205      0.099      0.921      -0.381       0.422\n",
      "Thriller                 0.1914      0.101      1.888      0.059      -0.007       0.390\n",
      "War                     -0.2517      0.215     -1.169      0.242      -0.674       0.170\n",
      "Western                 -0.6589      0.342     -1.926      0.054      -1.330       0.012\n",
      "Country_count           -0.1996      0.039     -5.067      0.000      -0.277      -0.122\n",
      "log_Adjusted_Budgets     0.9678      0.033     29.000      0.000       0.902       1.033\n",
      "NLP_Score                0.0404      0.008      4.876      0.000       0.024       0.057\n",
      "==============================================================================\n",
      "Omnibus:                      516.709   Durbin-Watson:                   1.967\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             1345.951\n",
      "Skew:                          -1.148   Prob(JB):                    5.38e-293\n",
      "Kurtosis:                       5.863   Cond. No.                     1.02e+16\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The smallest eigenvalue is 2.79e-25. This might indicate that there are\n",
      "strong multicollinearity problems or that the design matrix is singular.\n",
      "Out of Sample R2 is : 0.489\n"
     ]
    }
   ],
   "source": [
    "data_model9 = data_budget[['log_Adjusted_BoxOffice', 'Runtime',\n",
    "        'Action','Adventure', 'Animation', 'Biography', 'Comedy', 'Crime', 'Documentary',\n",
    "       'Drama', 'Family', 'Fantasy', 'Film-Noir', 'History', 'Horror', 'Music',\n",
    "       'Musical', 'Mystery', 'News', 'Romance', 'Sci-Fi', 'Short', 'Sport',\n",
    "       'Thriller', 'War', 'Western', 'Country_count','log_Adjusted_Budgets','NLP_Score']]\n",
    "\n",
    "X = data_model9.drop('log_Adjusted_BoxOffice',axis = 1)\n",
    "y = data_model9['log_Adjusted_BoxOffice']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3,random_state = 1)\n",
    "\n",
    "\n",
    "lr_model1 = sm.OLS(y_train, sm.add_constant(X_train))\n",
    "lr_est1 = lr_model1.fit()\n",
    "print(lr_est1.summary())\n",
    "\n",
    "# Out of Sample\n",
    "pred = lr_est1.predict(sm.add_constant(X_test))\n",
    "oosr = 1 - sum([x*x for x in (pred-y_test)])/sum([x*x for x in (sum(y_train)/len(y_train)-y_test)])\n",
    "print('Out of Sample R2 is : %s' %round(oosr,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              OLS Regression Results                              \n",
      "==================================================================================\n",
      "Dep. Variable:     log_Adjusted_BoxOffice   R-squared:                       0.513\n",
      "Model:                                OLS   Adj. R-squared:                  0.507\n",
      "Method:                     Least Squares   F-statistic:                     89.24\n",
      "Date:                    Wed, 05 Dec 2018   Prob (F-statistic):               0.00\n",
      "Time:                            00:10:32   Log-Likelihood:                -4713.7\n",
      "No. Observations:                    2399   AIC:                             9485.\n",
      "Df Residuals:                        2370   BIC:                             9653.\n",
      "Df Model:                              28                                         \n",
      "Covariance Type:                nonrobust                                         \n",
      "========================================================================================\n",
      "                           coef    std err          t      P>|t|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------------\n",
      "const                   -1.9114      0.279     -6.848      0.000      -2.459      -1.364\n",
      "Runtime                  0.0103      0.003      3.944      0.000       0.005       0.015\n",
      "Action                   0.0129      0.107      0.120      0.904      -0.198       0.224\n",
      "Adventure                0.1313      0.115      1.138      0.255      -0.095       0.358\n",
      "Animation                0.0937      0.204      0.458      0.647      -0.307       0.495\n",
      "Biography                0.2395      0.159      1.511      0.131      -0.071       0.550\n",
      "Comedy                   0.2779      0.097      2.858      0.004       0.087       0.469\n",
      "Crime                   -0.2012      0.103     -1.959      0.050      -0.403       0.000\n",
      "Documentary              0.0529      0.331      0.160      0.873      -0.596       0.702\n",
      "Drama                   -0.2832      0.094     -3.010      0.003      -0.468      -0.099\n",
      "Family                   0.5330      0.153      3.494      0.000       0.234       0.832\n",
      "Fantasy                 -0.0821      0.127     -0.648      0.517      -0.331       0.166\n",
      "Film-Noir             1.159e-16   4.64e-16      0.250      0.803   -7.95e-16    1.03e-15\n",
      "History                 -0.1399      0.215     -0.651      0.515      -0.561       0.281\n",
      "Horror                   0.4924      0.139      3.531      0.000       0.219       0.766\n",
      "Music                    0.3647      0.183      1.990      0.047       0.005       0.724\n",
      "Musical                 -0.2464      0.271     -0.911      0.362      -0.777       0.284\n",
      "Mystery                  0.3754      0.124      3.027      0.002       0.132       0.619\n",
      "News                    -0.0203      1.771     -0.011      0.991      -3.493       3.452\n",
      "Romance                  0.2435      0.093      2.609      0.009       0.060       0.426\n",
      "Sci-Fi                  -0.1430      0.124     -1.154      0.249      -0.386       0.100\n",
      "Short                 7.103e-17   1.62e-16      0.439      0.661   -2.47e-16    3.89e-16\n",
      "Sport                   -0.0116      0.204     -0.057      0.955      -0.411       0.388\n",
      "Thriller                 0.1864      0.101      1.847      0.065      -0.011       0.384\n",
      "War                     -0.2637      0.214     -1.231      0.218      -0.684       0.156\n",
      "Western                 -0.6452      0.340     -1.895      0.058      -1.313       0.023\n",
      "Country_count           -0.2107      0.039     -5.369      0.000      -0.288      -0.134\n",
      "log_Adjusted_Budgets     0.9782      0.033     29.352      0.000       0.913       1.044\n",
      "Director_Score           0.1075      0.037      2.932      0.003       0.036       0.179\n",
      "Writer_Score             0.2500      0.056      4.481      0.000       0.141       0.359\n",
      "Actor_Score              0.0210      0.009      2.263      0.024       0.003       0.039\n",
      "==============================================================================\n",
      "Omnibus:                      503.791   Durbin-Watson:                   1.969\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             1278.117\n",
      "Skew:                          -1.130   Prob(JB):                    2.89e-278\n",
      "Kurtosis:                       5.771   Cond. No.                     1.02e+16\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The smallest eigenvalue is 2.78e-25. This might indicate that there are\n",
      "strong multicollinearity problems or that the design matrix is singular.\n",
      "Out of Sample R2 is : 0.5\n"
     ]
    }
   ],
   "source": [
    "data_model10 = data_budget[['log_Adjusted_BoxOffice', 'Runtime',\n",
    "        'Action','Adventure', 'Animation', 'Biography', 'Comedy', 'Crime', 'Documentary',\n",
    "       'Drama', 'Family', 'Fantasy', 'Film-Noir', 'History', 'Horror', 'Music',\n",
    "       'Musical', 'Mystery', 'News', 'Romance', 'Sci-Fi', 'Short', 'Sport',\n",
    "       'Thriller', 'War', 'Western', 'Country_count','log_Adjusted_Budgets','Director_Score','Writer_Score','Actor_Score']]\n",
    "\n",
    "X = data_model10.drop('log_Adjusted_BoxOffice',axis = 1)\n",
    "y = data_model10['log_Adjusted_BoxOffice']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3,random_state = 1)\n",
    "\n",
    "\n",
    "lr_model1 = sm.OLS(y_train, sm.add_constant(X_train))\n",
    "lr_est1 = lr_model1.fit()\n",
    "print(lr_est1.summary())\n",
    "\n",
    "# Out of Sample\n",
    "pred = lr_est1.predict(sm.add_constant(X_test))\n",
    "oosr = 1 - sum([x*x for x in (pred-y_test)])/sum([x*x for x in (sum(y_train)/len(y_train)-y_test)])\n",
    "print('Out of Sample R2 is : %s' %round(oosr,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Model1: CV Accuracy: 57.563 | Testing Accuracy: 58.892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wwengm/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "data_model11 = data_budget[['Runtime',\n",
    "        'Action','Adventure', 'Animation', 'Biography', 'Comedy', 'Crime', 'Documentary',\n",
    "       'Drama', 'Family', 'Fantasy', 'Film-Noir', 'History', 'Horror', 'Music',\n",
    "       'Musical', 'Mystery', 'News', 'Romance', 'Sci-Fi', 'Short', 'Sport',\n",
    "       'Thriller', 'War', 'Western', 'Country_count','Director_Score','Writer_Score','Actor_Score']]\n",
    "\n",
    "data_model11['Profit_binary'] = data_budget['log_Adjusted_BoxOffice'] - data_budget['log_Adjusted_Budgets'] > 0\n",
    "\n",
    "X = data_model11.drop('Profit_binary',axis = 1)\n",
    "y = data_model11['Profit_binary']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3,random_state = 1)\n",
    "\n",
    "\n",
    "lr_clf = LogisticRegression()\n",
    "scores = cross_val_score(lr_clf, X_train, y_train, cv=5)\n",
    "\n",
    "lr_clf.fit(X_train, y_train)\n",
    "y_pred = lr_clf.predict(X_test)\n",
    "tst_acc = accuracy_score(y_test, y_pred) * 100\n",
    "cv_acc = np.mean(scores) * 100\n",
    "print('Baseline Model1: CV Accuracy: %0.3f | Testing Accuracy: %0.3f' % (cv_acc,tst_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
